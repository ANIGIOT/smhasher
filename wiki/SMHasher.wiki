#summary SMHasher info

== Sanity Tests ==

== Performance Tests ==

Applications that use hash functions to generate semi-unique identifiers for large blocks of data care most about the bulk speed of a hash function, while applications that use hash functions to implement efficient hash tables for short keys care most about the total time needed to hash a key. SMHasher tests both -

To determine how fast a hash function can consume data, create a large block of random data and measure how long it takes to hash it. Due to caching and interrupts and other sources of noise in an average PC, repeat the test a large number of times to ensure we get a clean run.

To determine how fast a hash function can completely hash a key (including function call overhead, code setup overhead, the hashing itself, finalization, and any other source of latency), generate a large number of tiny keys and measure the number of cycles needed to hash them some large number of times and track the fastest time out of all the runs.


== Differential Tests ==

For all possible small N-bit subsets of a M-bit key, generate 1000 random key pairs that differ in only those N bits and see if any of them hash to the same value. If so, those N bits tend to cancel out inside the hash function and generate more collisions than expected.

SuperFastHash fails this test badly - a large number of N-bit patterns can cause collisions with high (over 50% in some cases) probability.


== Avalanche Tests ==

Do all key bits affect all hash bits equally? Does flipping a key bit cause all hash bits to flip with a 50/50 probability?

For an N-bit hash function, SMHasher generates 2 million N*2-bit keys and flips each bit of each key, comparing the original hash of the key and the hash of the flipped-bit key. It computes how far the flipping of each output bit is from an ideal 50/50 probability, and reports the worst deviation or 'bias' from ideal it found - 0% indicates perfect 50/50 probability, 100% indicates that the output bit either never or always flipped.

Due to random fluctuations we generally won't see exactly 50/50 even with true random inputs, but 2 million tests is enough to measure bias down to about 0.25%

== Cyclic Keyset Tests ==

Generate 10 million keys consisting of N repetitions of M bytes, hash them, and test collision & distribution properties. If identical blocks of the key tend to cancel out inside the hash function, this should produce a lot more collisions than expected.

These keysets break MurmurHash2, and were the motivation for creating MurmurHash3.

== Sparse Keyset Tests ==

These keysets are similar to the ones generated by Bob Jenkins' 'frog.c' test code.

== Permutation Keyset Tests ==

Ten blocks of key data can be assembled into a key in ~3.6 million ways. If each block only has a single bit set, the resulting keys are very hard to hash well - there's just not much data there to work with.

== Windowed Keyset Tests ==

This is more of a sanity check than a difficult keyset to hash. Given an N-bit hash, generate all possible N*2-bit keys that have a contiguous 20-bit-wide "window" of bits set to all possible 2^20 values.

If nearby bits in the key tend to cancel each other out in the hash function, this should produce a lot more random collisions than expected.

== Text Keyset Tests ==

This is a convenient place for users to create keyset patterns that match those found in their own applications.

Given a prefix string P, a suffix string S, a set of characters C, and a length value L, generate all possible keys of the form P+[L characters from C]+S and test their collision + distribution properties.